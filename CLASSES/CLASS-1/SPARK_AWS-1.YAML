1 - Steps in a full machine learning project:
    1. Define the problem.
    2. Prepare Data.
    3. Evaluate Algorithms.
    4. feature Engineering.
    5. Model Selection.
    6. Model Training.
    7. experimentation.
    8. Model Evaluation.
    9. Model Deployment.
    10. Model Monitoring.
    11. Model Maintenance.
    12. Model Update.
    13. Model Retraining.
    14. Model Versioning.

2 - example in practice step by step some steps:
    2.1. Model Deployment:
        - Prepare for Deployment:
            Model Serialization: Save the trained model using formats like pickle, joblib, or ONNX.
              Example: Save model as churn_model.pkl.
            Set Dependencies: Ensure required libraries (e.g., xgboost, pandas) are specified in a requirements.txt.
        
        - Develop Deployment Environment:
            Infrastructure:
              Use cloud services (e.g., AWS, Azure, GCP) or on-premise servers.
            Choose a deployment method: Batch processing or API-based predictions.
            Containerization:
              Use Docker to containerize the application.
              Create a Dockerfile specifying base images and dependencies.
        
        - Create a Model Inference Pipeline:
            Build API: Use Flask or FastAPI to create an endpoint.
              Example: /predict endpoint accepts customer data and returns churn probability.
        
        - Deploy to Production:
            Local Deployment: Run the Docker container locally for testing.
            Cloud Deployment: Push Docker image to a container registry (e.g., AWS ECR, Docker Hub) and deploy using a cloud service.
              Use Kubernetes or AWS ECS for orchestration.
            CI/CD Pipeline: Automate deployment with GitHub Actions or Jenkins.
      
        - Monitor and Maintain:
            Monitoring Tools:
              Use services like Prometheus or Datadog to track API performance and latency.
              Monitor prediction drift to detect when model retraining is needed.
            Feedback Loop:
              Continuously collect new data and validate predictions to improve the model.
        
3 - three sets of models with example:
  - training set: 70% of the data used to train the model.
  - validation set: 15% of the data used to tune the model.
      - how to tune the model:
          - Hyperparameter Tuning: Use techniques like grid search, random search, or Bayesian optimization to find the best hyperparameters.
          - Cross-Validation: Split the training set into k folds and train the model on k-1 folds while validating on the remaining fold.
          - Early Stopping: Monitor the validation loss and stop training when it starts to increase.
  - test set: 15% of the data used to evaluate the model.
  
  - example:
    from sklearn.model_selection import train_test_split

    # Splitting the dataset
    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)
    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)


  